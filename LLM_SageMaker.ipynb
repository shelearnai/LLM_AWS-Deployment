{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad966584-a195-487d-a642-67bab71e55cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.11/site-packages (2.227.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (23.2.0)\n",
      "Collecting boto3<2.0,>=1.34.142 (from sagemaker)\n",
      "  Downloading boto3-1.35.28-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (24.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.2.2)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.21.1)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker) (3.11.0)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.26.19)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.66.5)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from sagemaker) (5.9.8)\n",
      "Collecting botocore<1.36.0,>=1.35.28 (from boto3<2.0,>=1.34.142->sagemaker)\n",
      "  Downloading botocore-1.35.28-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.34.142->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.34.142->sagemaker) (0.10.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (2024.7.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Downloading boto3-1.35.28-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.35.28-py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.131\n",
      "    Uninstalling botocore-1.34.131:\n",
      "      Successfully uninstalled botocore-1.34.131\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.131\n",
      "    Uninstalling boto3-1.34.131:\n",
      "      Successfully uninstalled boto3-1.34.131\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "aiobotocore 2.13.2 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.35.28 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.1 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-features 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "langchain-aws 0.1.16 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.35.28 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.35.28 botocore-1.35.28\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39401f6-9967-40df-addc-9f51f6e5950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sage maker role arn: arn:aws:iam::608862829472:role/service-role/AmazonSageMaker-ExecutionRole-20240927T091375\n",
      "sagemaker session region:ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess=sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket=sess.default_bucket\n",
    "\n",
    "try:\n",
    "    role=sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam=boto3.client('iam')\n",
    "    role=iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess=sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "print(f\"sage maker role arn: {role}\")\n",
    "print(f\"sagemaker session region:{sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766ac1a5-bf7d-41b1-91f4-7b4c2f10efa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.0-tgi0.8.2-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"0.8.2\"\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5942124-5c44-46d1-92c2-6754bf26136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::608862829472:role/service-role/AmazonSageMaker-ExecutionRole-20240927T091375\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68bc1def-609b-43f3-b5ce-1205991cef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!{'score': 0.13097743690013885, 'start': 24, 'end': 33, 'answer': 'SageMaker'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# Define the Hugging Face model ID and task\n",
    "hub = {\n",
    "    'HF_MODEL_ID': 'distilbert-base-cased-distilled-squad',  # Correct model ID\n",
    "    'HF_TASK': 'question-answering'\n",
    "}\n",
    "\n",
    "# Create HuggingFaceModel instance\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub,\n",
    "    role=role,\n",
    "    transformers_version='4.26',\n",
    "    pytorch_version='1.13',\n",
    "    py_version='py39'\n",
    ")\n",
    "\n",
    "# Deploy the model to an ml.t3.medium instance\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large'\n",
    ")\n",
    "\n",
    "# Define input data for prediction\n",
    "data = {\n",
    "    \"inputs\": {\n",
    "        \"question\": \"What is used for inference?\",\n",
    "        \"context\": \"This model is used with SageMaker to answer the questions.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform prediction using the deployed model\n",
    "result = predictor.predict(data)\n",
    "\n",
    "# Print the prediction result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9952db8-0c89-49a5-b291-75f5cf0437c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------![{'label': 'POSITIVE', 'score': 0.999879002571106}]\n"
     ]
    }
   ],
   "source": [
    "#For classification\n",
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "hub = {\n",
    "    'HF_MODEL_ID': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
    "    'HF_TASK': 'text-classification'\n",
    "}\n",
    "# Create HuggingFaceModel instance\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub,\n",
    "    role=role,\n",
    "    transformers_version='4.26',\n",
    "    pytorch_version='1.13',\n",
    "    py_version='py39'\n",
    ")\n",
    "# Deploy the model to an ml.t3.medium instance\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large'\n",
    ")\n",
    "# Input data for text classification\n",
    "data = {\n",
    "    \"inputs\": \"I love this movie, it is awesome!\"\n",
    "}\n",
    "\n",
    "# Perform prediction\n",
    "result = predictor.predict(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3f031ac-2636-4896-abe6-eac2c91d6ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------![{'generated_text': 'The future of AI is now in our hands.\" They are confident that a solution will come within 10 years, he said.\\n\\n\\n\\n\"Some of the key points in technology could be changed. There will be good, more efficient AI development'}]\n"
     ]
    }
   ],
   "source": [
    "# text generation\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "hub = {\n",
    "    'HF_MODEL_ID': 'distilgpt2',\n",
    "    'HF_TASK': 'text-generation'\n",
    "}\n",
    "\n",
    "role = 'nn' #the role created in IAM with SageMaker Full Access\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub,\n",
    "    role='nn',\n",
    "    transformers_version='4.26',\n",
    "    pytorch_version='1.13',\n",
    "    py_version='py39'\n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large'\n",
    ")\n",
    "\n",
    "data = {\n",
    "    \"inputs\": \"The future of AI is\"\n",
    "}\n",
    "\n",
    "result = predictor.predict(data)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb8ca8-8ca9-41ed-aa3c-31c91dc0eaca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
